{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMpVkGHOSlgG"
      },
      "source": [
        "# Create Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5YROfHAXIpx",
        "outputId": "d9829bb3-a3a4-4135-e7fd-c07b38409a42"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# move to where the codebase is located\n",
        "%cd /content/drive/MyDrive/Final_Project/code/Fusion_Network_For_Infant_Pose_Estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t2S_7lg-vb4W"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset,TensorDataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import math\n",
        "import sys\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import utils.utils as ut\n",
        "from utils.utils_ds import *\n",
        "\n",
        "class SMaLDataset(Dataset):\n",
        "    joint_num = 14\n",
        "\n",
        "    joints_name = (\n",
        "        \"R_Ankle\", \"R_Knee\", \"R_Hip\", \"L_Hip\", \"L_Knee\", \"L_Ankle\", \"R_Wrist\", \"R_Elbow\", \"R_Shoulder\", \"L_Shoulder\",\n",
        "        \"L_Elbow\", \"L_Wrist\", \"Thorax\", \"Head\"\n",
        "        )\n",
        "\n",
        "    flip_pairs_name = (\n",
        "        ('R_Hip', 'L_Hip'), ('R_Knee', 'L_Knee'), ('R_Ankle', 'L_Ankle'),\n",
        "        ('R_Shoulder', 'L_Shoulder'), ('R_Elbow', 'L_Elbow'), ('R_Wrist', 'L_Wrist')\n",
        "      )\n",
        "    skels_name = (\n",
        "        ('Thorax', 'Head'),\n",
        "        ('Thorax', 'R_Shoulder'), ('R_Shoulder', 'R_Elbow'), ('R_Elbow', 'R_Wrist'),\n",
        "        ('Thorax', 'L_Shoulder'), ('L_Shoulder', 'L_Elbow'), ('L_Elbow', 'L_Wrist'),\n",
        "        ('R_Hip', 'R_Knee'), ('R_Knee', 'R_Ankle'),\n",
        "        ('L_Hip', 'L_Knee'), ('L_Knee', 'L_Ankle'),\n",
        "      )\n",
        "\n",
        "    skels_idx = ut.nameToIdx(skels_name, joints_name=joints_name)\n",
        "    flip_pairs = ut.nameToIdx(flip_pairs_name, joints_name)\n",
        "\n",
        "    def __init__(self, img_dir,fold,modality='both',covering=(['uncovered','cover1','cover2']),phase=\"train\",\n",
        "                 clip=False,mean=None,std=None,aug_param=None,swap_channels=False):\n",
        "        self.covering = covering\n",
        "        self.num_cover = len(self.covering)\n",
        "        self.modality = modality\n",
        "        self.sz_pch = (256,256)\n",
        "        self.out_shp = (64,64)\n",
        "        self.aug_param = aug_param\n",
        "        self.phase = phase\n",
        "        self.img_dir = img_dir + f\"{fold}/{phase}\"\n",
        "        self.swap_channels = swap_channels\n",
        "\n",
        "        self.img_labels = np.load(f'{self.img_dir}/joints.npy')\n",
        "        self.img_labels[:,:,0] = self.img_labels[:,:,0]*self.sz_pch[0]\n",
        "        self.img_labels[:,:,1] = self.img_labels[:,:,1]*self.sz_pch[1]\n",
        "        self.imgs = {}\n",
        "        for cover in self.covering:\n",
        "          self.imgs[cover] = np.load(f'{self.img_dir}/{cover}.npy')\n",
        "          if clip:\n",
        "            self.imgs[cover][:,:,:,0] = np.clip(self.imgs[cover][:,:,:,0],400,800)\n",
        "\n",
        "        if mean is None or std is None:\n",
        "          means = []\n",
        "          stds = []\n",
        "          for cover in self.covering:\n",
        "            means.append(self.imgs[cover].mean(axis=(0,1,2)))\n",
        "            stds.append(self.imgs[cover].var(axis=(0,1,2)))\n",
        "          self.mean = np.vstack(means).mean(axis=0)\n",
        "          self.std = np.sqrt(np.vstack(stds).mean(axis=0))\n",
        "        else:\n",
        "          self.mean = mean\n",
        "          self.std = std\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.img_labels.shape[0]*self.num_cover\n",
        "\n",
        "    def __getitem__(self, idx,debug=False):\n",
        "        i = idx//self.num_cover\n",
        "        cover = self.covering[idx%self.num_cover]\n",
        "\n",
        "        label = self.img_labels[i, :, :]\n",
        "        img = self.imgs[cover][i,:,:,:]\n",
        "        img = cv2.resize(img, dsize=self.sz_pch, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        img_height, img_width, img_channel = img.shape\n",
        "        bb = [0,0,img_width,img_height]  # full image bb , make square bb\n",
        "        bb = ut.adj_bb(bb, rt_xy=1)\n",
        "\n",
        "        if self.phase=='train':\n",
        "            scale, rot, do_flip, color_scale, do_occlusion = get_aug_config_by_values(self.aug_param)\n",
        "        else:\n",
        "            scale, rot, do_flip, color_scale, do_occlusion = 1.0, 0.0, False, [1.0, 1.0, 1.0], False\n",
        "\n",
        "        img_patch, trans = generate_patch_image(img, bb, do_flip, scale, rot, do_occlusion, input_shape=self.sz_pch)\n",
        "\n",
        "        if img_patch.ndim<3:\n",
        "          img_channels = 1        # add one channel\n",
        "          img_patch = img_patch[..., None]\n",
        "        else:\n",
        "          if \"RGB\"in self.modality:                 #changed by us maximum fuse modality is 3\n",
        "              img_channels=3\n",
        "          else:\n",
        "              img_channels = img_patch.shape[2]\n",
        "        for i in range(img_channels):\n",
        "          img_patch[:, :, i] = img_patch[:, :, i] * color_scale[i]\n",
        "        jt_patch = label.copy()\n",
        "\n",
        "        if do_flip:\n",
        "          jt_patch[:, 0] = img_width - label[:, 0] - 1\n",
        "          for pair in SMaLDataset.flip_pairs:\n",
        "            jt_patch[pair[0], :], jt_patch[pair[1], :] = jt_patch[pair[1], :].copy(), jt_patch[pair[0], :].copy()\n",
        "\n",
        "        for i in range(len(jt_patch)):  #  jt trans\n",
        "          jt_patch[i, 0:2] = trans_point2d(jt_patch[i, 0:2], trans)\n",
        "\n",
        "        stride = self.sz_pch[0]/self.out_shp[1]  # jt shrink\n",
        "        joints_hm = jt_patch/stride\n",
        "\n",
        "        jt_vis = np.ones(self.joint_num)\n",
        "        for i in range(len(jt_patch)):        # only check 2d here\n",
        "          jt_vis[i] *= (\n",
        "              (jt_patch[i, 0] >= 0) & \\\n",
        "              (jt_patch[i, 0] < self.sz_pch[0]) & \\\n",
        "              (jt_patch[i, 1] >= 0) & \\\n",
        "              (jt_patch[i, 1] < self.sz_pch[1])\n",
        "          )  # nice filtering  all in range visibile\n",
        "\n",
        "        hms, jt_wt = generate_target(joints_hm, jt_vis, sigma=1, sz_hm=self.out_shp)\n",
        "\n",
        "        idx_t, idx_h = ut.nameToIdx(('Thorax', 'Head'), self.joints_name)\n",
        "        l_std_hm = np.linalg.norm(joints_hm[idx_h] - joints_hm[idx_t])\n",
        "        l_std_ori = np.linalg.norm(label[idx_h] - label[idx_t])\n",
        "\n",
        "        trans_tch = transforms.Compose([transforms.ToTensor(),\n",
        "          transforms.Normalize(mean=self.mean, std=self.std)]\n",
        "        )\n",
        "        pch_tch = trans_tch(img_patch)\n",
        "\n",
        "        hms_tch = torch.from_numpy(hms)\n",
        "        img_mean = self.mean\n",
        "        img_std = self.std\n",
        "\n",
        "        if self.modality=='depth':\n",
        "          pch_tch = pch_tch[[0],:,:]\n",
        "          img_mean = self.mean[0]\n",
        "          img_std = self.std[0]\n",
        "        elif self.modality=='psm':\n",
        "          pch_tch = pch_tch[[1],:,:]\n",
        "          img_mean = self.mean[1]\n",
        "          img_std = self.std[1]\n",
        "        else:\n",
        "          if self.swap_channels:\n",
        "            pch_tch[[0],:,:],pch_tch[[1],:,:] = pch_tch[[1],:,:],pch_tch[[0],:,:]\n",
        "            self.mean[0],self.mean[1] = self.mean[1],self.mean[0]\n",
        "            self.std[0],self.std[1] = self.std[1],self.std[0]\n",
        "\n",
        "        result = {\n",
        "            'original_img':img,\n",
        "            'pch':pch_tch,\n",
        "            'hms': hms_tch,\n",
        "            'joints_vis': jt_wt,\n",
        "            'joints_pch': jt_patch.astype(np.float32),       \n",
        "            'l_std_hm':l_std_hm.astype(np.float32),\n",
        "            'l_std_ori':l_std_ori.astype(np.float32),\n",
        "            'joints_ori': label[:,:2].astype(np.float32),\n",
        "            'bb': bb.astype(np.float32),\n",
        "            'mean' :img_mean,\n",
        "            'std':img_std\n",
        "        }\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "F6QF-MqxcJQq"
      },
      "outputs": [],
      "source": [
        "def get_aug_config_by_values(aug_param):\n",
        "\tscale_factor = aug_param['scale_factor']\n",
        "\trot_factor = aug_param['rot_factor']\n",
        "\tcolor_factor = aug_param['color_factor']\n",
        "\tdo_occlusion = aug_param[\"do_occlusion\"]\n",
        "\n",
        "\tscale = np.clip(np.random.randn(), -1.0, 1.0) * scale_factor + 1.0\n",
        "\trot = np.clip(np.random.randn(), -2.0,\n",
        "\t              2.0) * rot_factor if random.random() <= 0.6 else 0        # -60 to 60\n",
        "\tdo_flip = random.random() <= 0.5\n",
        "\tc_up = 1.0 + color_factor\n",
        "\tc_low = 1.0 - color_factor\n",
        "\tcolor_scale = [random.uniform(c_low, c_up), random.uniform(c_low, c_up), random.uniform(c_low, c_up)]\n",
        "\n",
        "\treturn scale, rot, do_flip, color_scale, do_occlusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMh-TIebWOpR"
      },
      "source": [
        "#Train Fusion Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kevtEMSo45Fm",
        "outputId": "afb90478-0ae1-4ecd-8162-014d21dcc63e"
      },
      "outputs": [],
      "source": [
        "!pip install configargparse dominate yacs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tl0rx_V8SveP"
      },
      "outputs": [],
      "source": [
        "def plotImage(ax, image):\n",
        "    if torch.is_tensor(image):\n",
        "        image = image.permute(1, 2, 0).cpu().numpy()\n",
        "    image = np.array(image)\n",
        "    # print(image.shape)\n",
        "    ax.imshow(image)\n",
        "\n",
        "def plotImage(ax, image,c):\n",
        "    if torch.is_tensor(image):\n",
        "        image = image.permute(1, 2, 0)[:,:,c].cpu().numpy()\n",
        "    image = np.array(image)\n",
        "    ax.imshow(image)\n",
        "\n",
        "def plot2DJoints(ax, joints2D, connectedJoints, jointColours, visJoints=None):\n",
        "    # Plot skeleton\n",
        "    for i in np.arange(len(connectedJoints)):\n",
        "        joint1 = connectedJoints[i, 0]\n",
        "        joint2 = connectedJoints[i, 1]\n",
        "        if visJoints is None or (visJoints[joint1] == 1 and visJoints[joint2] == 1):\n",
        "            x, y = [\n",
        "                np.array(\n",
        "                    [\n",
        "                        joints2D[connectedJoints[i, 0], j],\n",
        "                        joints2D[connectedJoints[i, 1], j],\n",
        "                    ]\n",
        "                )\n",
        "                for j in range(2)\n",
        "            ]\n",
        "            ax.plot(x, y, lw=2, c=jointColours[i])\n",
        "\n",
        "    # Plot joint coordiantes\n",
        "    for i in range(len(joints2D)):\n",
        "        scatterColour = \"black\" if visJoints is None or visJoints[i] == 1 else \"orange\"\n",
        "        ax.scatter(joints2D[i, 0], joints2D[i, 1], c=scatterColour)\n",
        "        # ax.text(\n",
        "        #     joints2D[i, 0], joints2D[i, 1]-5, i)\n",
        "\n",
        "def plot2DJointsPredAndTruth(ax, joints2DPrd, joints2DTruth, connectedJoints, visJoints=None):\n",
        "    joints2Dlist = [joints2DTruth, joints2DPrd]\n",
        "    jointColourslist = [SMaL_configs[\"gtjointColours\"],SMaL_configs[\"predjointColours\"]]\n",
        "    scatterColourList = [\"yellow\",\"blue\"]\n",
        "    markerList = [\"o\",\"d\"]\n",
        "    # Plot skeleton\n",
        "    for m in range(2):\n",
        "      joints2D = joints2Dlist[m]\n",
        "      scatterColour = scatterColourList[m]\n",
        "      marker = markerList[m]\n",
        "      # Plot joint coordiantes\n",
        "      for i in range(len(joints2D)):\n",
        "          scatterColour = scatterColour if visJoints is None or visJoints[i] == 1 else \"orange\"\n",
        "          ax.scatter(joints2D[i, 0], joints2D[i, 1], c=scatterColour, marker=marker, alpha=0.5)\n",
        "          # ax.text(\n",
        "          #     joints2D[i, 0], joints2D[i, 1]-5, i)\n",
        "    for m in range(2):\n",
        "      joints2D = joints2Dlist[m]\n",
        "      jointColours = jointColourslist[m]\n",
        "      for i in np.arange(len(connectedJoints)):\n",
        "          joint1 = connectedJoints[i, 0]\n",
        "          joint2 = connectedJoints[i, 1]\n",
        "          if visJoints is None or (visJoints[joint1] == 1 and visJoints[joint2] == 1):\n",
        "              x, y = [\n",
        "                  np.array(\n",
        "                      [\n",
        "                          joints2D[connectedJoints[i, 0], j],\n",
        "                          joints2D[connectedJoints[i, 1], j],\n",
        "                      ]\n",
        "                  )\n",
        "                  for j in range(2)\n",
        "              ]\n",
        "              ax.plot(x, y, lw=2, c=jointColours[i],  alpha=0.5)\n",
        "\n",
        "\n",
        "def save_pred(\n",
        "    input_img, pred, truth, i, sv_dir, vis_joints\n",
        "):\n",
        "    fname = sv_dir+\"/\"+str(i) + '.jpg'\n",
        "    numJoints = SMaL_configs[\"numJoints\"]\n",
        "    connectedJoints = SMaL_configs[\"connectedJoints\"]\n",
        "    jointColours = SMaL_configs[\"jointColours\"]\n",
        "    numRows = 1\n",
        "    ax = plt.subplot(numRows, 1, 1)\n",
        "    ax.set_title(\"Output 2D\")\n",
        "    plotImage(ax, input_img, 0)\n",
        "    plot2DJointsPredAndTruth(\n",
        "      ax,\n",
        "      pred,\n",
        "      truth,\n",
        "      connectedJoints,\n",
        "      vis_joints\n",
        "    )\n",
        "    plt.savefig(fname)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pka-y1O-nycq"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "2d pose estimation handling\n",
        "'''\n",
        "\n",
        "import utils.vis as vis\n",
        "import utils.utils as ut\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import json\n",
        "from os import path\n",
        "import os\n",
        "from utils.logger import Colorlogger\n",
        "from utils.utils_tch import get_model_summary\n",
        "from core.loss import JointsMSELoss\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "import time\n",
        "from utils.utils_ds import accuracy, flip_back\n",
        "from utils.visualizer import Visualizer\n",
        "\n",
        "\n",
        "def train(loader, model, criterion, optimizer, epoch, n_iter=-1, logger=None, opts=None, visualizer=None):\n",
        "  '''\n",
        "  iter through epoch , return rst{'acc', loss'} each as list can be used outside for updating.\n",
        "  :param loader:\n",
        "  :param model:\n",
        "  :param criterion:\n",
        "  :param optimizer:\n",
        "  :param epoch:  for print infor\n",
        "  :param n_iter: the iteration wanted, -1 for all iters\n",
        "  :param opts: keep some additional controls\n",
        "  :param visualizer: for visualizer\n",
        "  :return:\n",
        "  '''\n",
        "\n",
        "  batch_time = ut.AverageMeter()\n",
        "  data_time = ut.AverageMeter()\n",
        "  losses = ut.AverageMeter()\n",
        "  acc = ut.AverageMeter()\n",
        "\n",
        "  # switch to train mode\n",
        "  model.train()\n",
        "  end = time.time()\n",
        "  li_loss = []\n",
        "  li_acc = []\n",
        "  for i, inp_dct in enumerate(loader):\n",
        "    # get items\n",
        "    if i>=n_iter and n_iter>0:    # break if iter is set and i is greater than that\n",
        "      break\n",
        "    input = inp_dct['pch']\n",
        "    target = inp_dct['hms']     # 14 x 64 x 1??\n",
        "    target_weight = inp_dct['joints_vis']\n",
        "\n",
        "    # measure data loading time     weight, visible or not\n",
        "    data_time.update(time.time() - end)\n",
        "\n",
        "    # compute output\n",
        "    outputs = model(input)      # no need to cuda it?\n",
        "    outputs=outputs[\"output\"]\n",
        "    target = target.cuda(non_blocking=True)                                  ######WITH GPU\n",
        "    target_weight = target_weight.cuda(non_blocking=True)                    ######WITH GPU\n",
        "\n",
        "    if isinstance(outputs, list):       # list multiple stage version\n",
        "      loss = criterion(outputs[0], target, target_weight)\n",
        "      for output in outputs[1:]:\n",
        "        loss += criterion(output, target, target_weight)\n",
        "    else:\n",
        "      output = outputs\n",
        "      loss = criterion(output, target, target_weight)\n",
        "\n",
        "\n",
        "    # compute gradient and do update step\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # measure accuracy and record loss\n",
        "    losses.update(loss.item(), input.size(0))\n",
        "    _, avg_acc, cnt, pred = accuracy(output.detach().cpu().numpy(),\n",
        "                                     target.detach().cpu().numpy())  # hm directly, with normalize with 1/10 dim,  pck0.5,  cnt: n_smp,  pred\n",
        "    acc.update(avg_acc, cnt)  # keep average acc\n",
        "\n",
        "    if visualizer and 0 == i % opts.update_html_freq:     # update current result, get vis dict\n",
        "      n_jt =  SMaL_configs[\"numJoints\"]\n",
        "      mod0 = opts.mod_src[0]\n",
        "      mean = inp_dct['mean']\n",
        "      std = inp_dct['std']\n",
        "      img_patch_vis = ut.ts2cv2(input[0], mean, std)  # to CV BGR, mean std control channel detach inside\n",
        "      # pseudo change\n",
        "      cm = getattr(cv2,SMaL_configs[\"dct_clrMap\"][mod0])\n",
        "      img_patch_vis = cv2.applyColorMap(img_patch_vis, cm)[...,::-1]  # RGB\n",
        "\n",
        "      # get pred\n",
        "      pred2d_patch = np.ones((n_jt, 3))  # 3rd for  vis\n",
        "      pred2d_patch[:, :2] = pred[0] / opts.out_shp[0] * opts.sz_pch[1]\n",
        "      img_skel = vis.vis_keypoints(img_patch_vis, pred2d_patch,  SMaL_configs[\"connectedJoints\"])\n",
        "\n",
        "      hm_gt = target[0].cpu().detach().numpy().sum(axis=0)    # HXW\n",
        "      hm_gt = ut.normImg(hm_gt)\n",
        "\n",
        "      hm_pred = output[0].detach().cpu().numpy().sum(axis=0)\n",
        "      hm_pred = ut.normImg(hm_pred)\n",
        "      img_cb = vis.hconcat_resize([img_skel, hm_gt, hm_pred])\n",
        "      vis_dict = {'img_cb': img_cb}\n",
        "      visualizer.display_current_results(vis_dict, epoch, False)\n",
        "\n",
        "    # measure elapsed time\n",
        "    batch_time.update(time.time() - end)\n",
        "    end = time.time()\n",
        "\n",
        "    if i % opts.print_freq == 0:\n",
        "      msg = 'Epoch: [{0}][{1}/{2}]\\t' \\\n",
        "            'Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s)\\t' \\\n",
        "            'Speed {speed:.1f} samples/s\\t' \\\n",
        "            'Data {data_time.val:.3f}s ({data_time.avg:.3f}s)\\t' \\\n",
        "            'Loss {loss.val:.5f} ({loss.avg:.5f})\\t' \\\n",
        "            'Accuracy {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
        "        epoch, i, len(loader), batch_time=batch_time,\n",
        "        speed=input.size(0) / batch_time.val,\n",
        "        data_time=data_time, loss=losses, acc=acc)\n",
        "      logger.info(msg)\n",
        "      li_loss.append(losses.val)   # the current loss\n",
        "      li_acc.append(acc.val)\n",
        "\n",
        "  return {'losses':li_loss, 'accs':li_acc}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J7JJvnq-2YfH"
      },
      "outputs": [],
      "source": [
        "def validate(loader, model, criterion, fold, n_iter=-1, logger=None, opts=None, if_svVis=False, visualizer=None):\n",
        "  '''\n",
        "  loop through loder, all res, get preds and gts and normled dist.\n",
        "  With flip test for higher acc.\n",
        "  for preds, bbs, jts_ori, jts_weigth out, recover preds_ori, dists_nmd, pckh( dist and joints_vis filter, , print, if_sv then save all these\n",
        "  :param loader:\n",
        "  :param ds_rd: the reader, givens the length and flip pairs\n",
        "  :param model:\n",
        "  :param criterion:\n",
        "  :param optimizer:\n",
        "  :param epoch:\n",
        "  :param n_iter:\n",
        "  :param logger:\n",
        "  :param opts:\n",
        "  :return:\n",
        "  '''\n",
        "  batch_time = ut.AverageMeter()\n",
        "  losses = ut.AverageMeter()\n",
        "  acc = ut.AverageMeter()\n",
        "\n",
        "  # switch to evaluate mode\n",
        "  model.eval()\n",
        "\n",
        "  # num_samples = ds_rd.n_smpl\n",
        "  n_jt =  SMaL_configs[\"numJoints\"]\n",
        "\n",
        "\n",
        "  # to accum rst\n",
        "  preds_hm = []\n",
        "  bbs = []\n",
        "  li_joints_ori = []\n",
        "  li_joints_vis = []\n",
        "  li_l_std_ori = []\n",
        "  with torch.no_grad():\n",
        "    end = time.time()\n",
        "    for i, inp_dct in enumerate(loader):\n",
        "      # compute output\n",
        "      input = inp_dct['pch']\n",
        "      target = inp_dct['hms']\n",
        "      target_weight = inp_dct['joints_vis']\n",
        "      gt = inp_dct[\"joints_pch\"]\n",
        "      bb = inp_dct['bb']\n",
        "      joints_ori = inp_dct['joints_ori']\n",
        "      l_std_ori = inp_dct['l_std_ori']\n",
        "      mean = inp_dct[\"mean\"]\n",
        "      std = inp_dct[\"std\"]\n",
        "      if i>= n_iter and n_iter>0:     # limiting iters\n",
        "        break\n",
        "      outputs = model(input)\n",
        "      outputs =outputs[\"output\"]\n",
        "      if isinstance(outputs, list):\n",
        "        output = outputs[-1]\n",
        "      else:\n",
        "        output = outputs\n",
        "      output_ori = output.clone()     # original output of original image\n",
        "\n",
        "      target = target.cuda(non_blocking=True)                                         ####withGPU\n",
        "      target_weight = target_weight.cuda(non_blocking=True)                           ####withGPU\n",
        "      loss = criterion(output, target, target_weight)\n",
        "\n",
        "      num_images = input.size(0)\n",
        "      # measure accuracy and record loss\n",
        "      losses.update(loss.item(), num_images)\n",
        "      _, avg_acc, cnt, pred_hm = accuracy(output.cpu().numpy(),\n",
        "                                       target.cpu().numpy())\n",
        "      acc.update(avg_acc, cnt)\n",
        "\n",
        "      # preds can be furhter refined with subpixel trick, but it is already good enough.\n",
        "      # measure elapsed time\n",
        "      batch_time.update(time.time() - end)\n",
        "      end = time.time()\n",
        "\n",
        "      # keep rst\n",
        "      preds_hm.append(pred_hm)        # already numpy, 2D\n",
        "      bbs.append(bb.numpy())\n",
        "      li_joints_ori.append(joints_ori.numpy())\n",
        "      li_joints_vis.append(target_weight.cpu().numpy())\n",
        "      li_l_std_ori.append(l_std_ori.numpy())\n",
        "\n",
        "      if if_svVis:\n",
        "        for j in range(num_images):\n",
        "          sv_dir = opts.vis_test_dir  # exp/vis/Human36M\n",
        "          idx_test = f'{fold}_{i}_{j}'  # image index\n",
        "          pred2d_patch = np.ones((n_jt, 3))  # 3rd for  vis\n",
        "          pred2d_patch[:,:2] = pred_hm[j] / opts.out_shp[0] * opts.sz_pch[1]      # only first\n",
        "          save_pred(input[j], pred2d_patch, gt[j], idx_test, sv_dir, target_weight[j])\n",
        "\n",
        "      if i % opts.print_freq == 0:\n",
        "        msg = 'Test: [{0}/{1}]\\t' \\\n",
        "              'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t' \\\n",
        "              'Loss {loss.val:.4f} ({loss.avg:.4f})\\t' \\\n",
        "              'Accuracy {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
        "          i, len(loader), batch_time=batch_time,\n",
        "          loss=losses, acc=acc)\n",
        "        logger.info(msg)\n",
        "\n",
        "  preds_hm = np.concatenate(preds_hm,axis=0)      # N x n_jt  x 2\n",
        "  bbs = np.concatenate(bbs, axis=0)\n",
        "  joints_ori = np.concatenate(li_joints_ori, axis=0)\n",
        "  joints_vis = np.concatenate(li_joints_vis, axis=0)\n",
        "  l_std_ori_all = np.concatenate(li_l_std_ori, axis=0)\n",
        "\n",
        "  preds_ori = ut.warp_coord_to_original(preds_hm, bbs, sz_out=opts.out_shp)\n",
        "  err_nmd = ut.distNorm(preds_ori,  joints_ori, l_std_ori_all)\n",
        "  ticks = np.linspace(0,1,11)   # 11 ticks\n",
        "  pck_all_1 = ut.pck(err_nmd, joints_vis, ticks=ticks)\n",
        "  ticks = np.linspace(0,0.5,11)   # 11 ticks\n",
        "  pck_all_05 = ut.pck(err_nmd, joints_vis, ticks=ticks)\n",
        "\n",
        "  # save to plain format for easy processing\n",
        "  rst = {\n",
        "    'preds_ori':preds_ori.tolist(),\n",
        "    'joints_ori':joints_ori.tolist(),\n",
        "    'l_std_ori_all': l_std_ori_all.tolist(),\n",
        "    'err_nmd': err_nmd.tolist(),\n",
        "    'pck1': pck_all_1.tolist(),\n",
        "    'pck05': pck_all_05.tolist()\n",
        "  }\n",
        "\n",
        "  return rst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4qxbn9b5QcPa"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "\n",
        "OK = '\\033[92m'\n",
        "WARNING = '\\033[93m'\n",
        "FAIL = '\\033[91m'\n",
        "END = '\\033[0m'\n",
        "\n",
        "PINK = '\\033[95m'\n",
        "BLUE = '\\033[94m'\n",
        "GREEN = OK\n",
        "RED = FAIL\n",
        "WHITE = END\n",
        "YELLOW = WARNING\n",
        "\n",
        "class ColorloggerLocal():\n",
        "    def __init__(self, log_dir, log_name='train_logs.txt'):\n",
        "        # one _logger, add one file logger one stream logger\n",
        "        self._logger = logging.getLogger(log_name)\n",
        "        self._logger.setLevel(logging.INFO)\n",
        "        log_file = os.path.join(log_dir, log_name)\n",
        "        if not os.path.exists(log_dir):\n",
        "            os.makedirs(log_dir)\n",
        "        file_log = logging.FileHandler(log_file, mode='a')\n",
        "        file_log.setLevel(logging.INFO)\n",
        "        console_log = logging.StreamHandler()\n",
        "        console_log.setLevel(logging.INFO)\n",
        "        formatter = logging.Formatter(\n",
        "            \"{}%(asctime)s{} %(message)s\".format(GREEN, END),\n",
        "            \"%m-%d %H:%M:%S\")\n",
        "        file_log.setFormatter(formatter)\n",
        "        console_log.setFormatter(formatter)\n",
        "        if not self._logger.hasHandlers():\n",
        "          self._logger.addHandler(file_log)\n",
        "          self._logger.addHandler(console_log)\n",
        "\n",
        "    def debug(self, msg):\n",
        "        self._logger.debug(str(msg))\n",
        "\n",
        "    def info(self, msg):\n",
        "        self._logger.info(str(msg))\n",
        "\n",
        "    def warning(self, msg):\n",
        "        self._logger.warning(WARNING + 'WRN: ' + str(msg) + END)\n",
        "\n",
        "    def critical(self, msg):\n",
        "        self._logger.critical(RED + 'CRI: ' + str(msg) + END)\n",
        "\n",
        "    def error(self, msg):\n",
        "        self._logger.error(RED + 'ERR: ' + str(msg) + END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WAVh2w8aYgB1"
      },
      "outputs": [],
      "source": [
        "SMaL_configs = {\n",
        "    \"numJoints\": 14,\n",
        "    \"connectedJoints\": np.array(\n",
        "        [\n",
        "            [0, 1],\n",
        "            [1, 2],\n",
        "            [3, 4],\n",
        "            [4, 5],\n",
        "            [6, 7],\n",
        "            [7, 8],\n",
        "            [9, 10],\n",
        "            [10, 11],\n",
        "            [8, 12],\n",
        "            [9, 12],\n",
        "            [12, 13]\n",
        "        ]\n",
        "    ),\n",
        "    \"headIndex\": 13,\n",
        "    \"jointNames\": (\n",
        "        \"R_Ankle\",\n",
        "        \"R_Knee\",\n",
        "        \"R_Hip\",\n",
        "        \"L_Hip\",\n",
        "        \"L_Knee\",\n",
        "        \"L_Ankle\",\n",
        "        \"R_Wrist\",\n",
        "        \"R_Elbow\",\n",
        "        \"R_Shoulder\",\n",
        "        \"L_Shoulder\",\n",
        "\t\t    \"L_Elbow\",\n",
        "        \"L_Wrist\",\n",
        "        \"Thorax\",\n",
        "        \"Head\"),\n",
        "    \"jointColours\": [\n",
        "        \"blue\",\n",
        "        \"blue\",\n",
        "        \"blue\",\n",
        "        \"red\",\n",
        "        \"red\",\n",
        "        \"red\",\n",
        "        \"green\",\n",
        "        \"green\",\n",
        "        \"green\",\n",
        "        \"blue\",\n",
        "        \"blue\",\n",
        "        \"blue\",\n",
        "        \"red\",\n",
        "        \"red\",\n",
        "    ],\n",
        "    \"gtjointColours\": [\n",
        "        \"yellow\"\n",
        "    ]*14,\n",
        "    \"predjointColours\": [\"blue\"]*14,\n",
        "    \"dct_clrMap\": {      # the name of cv2 color map\n",
        "\t\t\"depth\":'COLORMAP_BONE',\n",
        "\t\t'RGB':'COLORMAP_BONE'\n",
        "\t  },\n",
        "    \"flip_pairs\": (\n",
        "\t\t('R_Hip', 'L_Hip'), ('R_Knee', 'L_Knee'), ('R_Ankle', 'L_Ankle'),\n",
        "\t\t('R_Shoulder', 'L_Shoulder'), ('R_Elbow', 'L_Elbow'), ('R_Wrist', 'L_Wrist')\n",
        "\t  \t),\n",
        "      \"skels_name\" : (\n",
        "\t\t# ('Pelvis', 'Thorax'),\n",
        "\t\t('Thorax', 'Head'),\n",
        "\t\t('Thorax', 'R_Shoulder'), ('R_Shoulder', 'R_Elbow'), ('R_Elbow', 'R_Wrist'),\n",
        "\t\t('Thorax', 'L_Shoulder'), ('L_Shoulder', 'L_Elbow'), ('L_Elbow', 'L_Wrist'),\n",
        "\t\t# ('Pelvis', 'R_Hip'),\n",
        "\t\t('R_Hip', 'R_Knee'), ('R_Knee', 'R_Ankle'),\n",
        "\t\t# ('Pelvis', 'L_Hip'),\n",
        "\t\t('L_Hip', 'L_Knee'), ('L_Knee', 'L_Ankle'),\n",
        "\t)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "setup options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZaPfhtuzCqz"
      },
      "outputs": [],
      "source": [
        "import opt\n",
        "\n",
        "opts = opt.parseArgs()\n",
        "\n",
        "opts.ds_fd = '/content/drive/MyDrive/Final_Project/dataset/SMaL-224/' # give your dataset folder here\n",
        "opts.sz_pch=[256, 256]\n",
        "opts.fc_depth = 50\n",
        "opts.cov_li = ['cover2','cover1', 'uncover']        # give the cover class you want here\n",
        "opts.prep = 'jt_hm'\n",
        "opts.n_thread = 5\n",
        "opts.if_pinMem = False\n",
        "opts.test_par = 'test'\n",
        "opts.mod_src = ['depth', \"psm\"]\n",
        "opts.out_shp = (64, 64, -1)\n",
        "opts.if_bb = True\n",
        "opts.gpu_ids = [0]\n",
        "opts.suffix_exp_train = 'suffix_for_current_training_execution'\n",
        "opts.if_test = False\n",
        "opts.exp_dir = '/content/drive/MyDrive/Final_Project/code/Fusion_Network_For_Infant_Pose_Estimation/output/' + opts.suffix_exp_train  # model output folder\n",
        "opts.log_dir = opts.exp_dir + \"/log\"\n",
        "opts.model_dir = opts.exp_dir + \"/model_dump\"\n",
        "opts.vis_dir = opts.exp_dir + \"/vis/test\"\n",
        "opts.rst_dir = opts.exp_dir + \"/result\"\n",
        "opts.vis_test_dir = opts.exp_dir + \"/vis/withgt\"\n",
        "opts.web_dir = opts.exp_dir + \"/web\"\n",
        "opts.input_nc = 2\n",
        "opts.bestpath_file = 'path_to_best_model_when_fin_tuning'  # fusion model trained with SLP dataset (weights to initialise the model for fine tunning)\n",
        "opts.print_freq = 5\n",
        "opts.end_epoch = 20\n",
        "opts.nmTest = \"test\"\n",
        "opts.model = \"HRposeFuseNetNewUnweighted_v2\"\n",
        "opts.modelConf = \"config/HRposeFuseNetNewUnweighted_v2\"\n",
        "opts.fuse_stage = 2         #2 or 3\n",
        "opts.fuse_type = \"iAFF\"         #add,concat,iAFF\n",
        "opts.swap_channels = False\n",
        "opts.fine_tune = False           #True if runing fine tuning\n",
        "opts.aug_param = {'rot_factor': 2, 'scale_factor': 0, 'do_occlusion': False,'color_factor':0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxSlf9nZQh10"
      },
      "outputs": [],
      "source": [
        "exec('from model.{} import get_pose_net'.format(opts.model))\n",
        "\n",
        "\n",
        "def optimizer_to(optim, device):\n",
        "    for param in optim.state.values():\n",
        "        # Not sure there are any global tensors in the state dict\n",
        "        if isinstance(param, torch.Tensor):\n",
        "            param.data = param.data.to(device)\n",
        "            if param._grad is not None:\n",
        "                param._grad.data = param._grad.data.to(device)\n",
        "        elif isinstance(param, dict):\n",
        "            for subparam in param.values():\n",
        "                if isinstance(subparam, torch.Tensor):\n",
        "                    subparam.data = subparam.data.to(device)\n",
        "                    if subparam._grad is not None:\n",
        "                        subparam._grad.data = subparam._grad.data.to(device)\n",
        "\n",
        "def main():\n",
        "\n",
        "  # get logger\n",
        "  if_test = opts.if_test\n",
        "  if if_test:\n",
        "    log_suffix = 'test'\n",
        "  else:\n",
        "    log_suffix = 'train'\n",
        "  logger = ColorloggerLocal(opts.log_dir, '{}_logs.txt'.format(log_suffix))    # avoid overwritting, will append\n",
        "  logger.propagate = False\n",
        "  opt.set_env(opts)\n",
        "  opt.print_options(opts, if_sv=True)\n",
        "  n_jt = SMaL_configs[\"numJoints\"]    #\n",
        "\n",
        "  # get model\n",
        "  model =  get_pose_net(in_ch=opts.input_nc, out_ch=n_jt, fuse_stage=opts.fuse_stage, fuse_type=opts.fuse_type, mod_src=opts.mod_src)\n",
        "\n",
        "  # define loss function (criterion) and optimizer\n",
        "  criterion = JointsMSELoss(      # try to not use weights                                                                    ######WITH GPU\n",
        "    use_target_weight=True\n",
        "  ).cuda()\n",
        "  # criterion = JointsMSELoss(      # try to not use weights\n",
        "  #   use_target_weight=True\n",
        "  # )\n",
        "\n",
        "\n",
        "  # for visualzier\n",
        "  if opts.display_id > 0:\n",
        "    visualizer = Visualizer(opts)  # only plot losses here, a loss log comes with it,\n",
        "  else:\n",
        "    visualizer = None\n",
        "  # get optmizer\n",
        "  best_perf = 0.0\n",
        "  last_epoch = -1\n",
        "  optimizer = Adam(model.parameters(), lr=opts.lr)\n",
        "  checkpoint_file = os.path.join(\n",
        "    opts.model_dir, 'checkpoint.pth')\n",
        "  last_fold = 0\n",
        "  if 0 == opts.start_epoch or not path.exists(checkpoint_file):  #    from scratch\n",
        "    begin_epoch =  0     # either set or not exist all the same from 0\n",
        "    if opts.fine_tune:\n",
        "        checkpoint_file = os.path.join(opts.bestpath_file,'model_best.pth')\n",
        "        checkpoint = torch.load(checkpoint_file)                                                                              ###########WITH GPU\n",
        "        # checkpoint = torch.load(checkpoint_file, map_location=torch.device('cpu'))\n",
        "        model.load_state_dict(checkpoint['state_dict'])  # here should be cuda setting\n",
        "    losses = []     # for tracking model performance.\n",
        "    accs= []\n",
        "  else:  # get chk points\n",
        "    logger.info(\"=> loading checkpoint '{}'\".format(checkpoint_file))\n",
        "    checkpoint = torch.load(checkpoint_file)\n",
        "    begin_epoch = checkpoint['epoch']\n",
        "    best_perf = checkpoint['perf']\n",
        "    last_epoch = checkpoint['epoch']\n",
        "    model.load_state_dict(checkpoint['state_dict'])  # here should be cuda setting\n",
        "    losses = checkpoint['losses']\n",
        "    accs = checkpoint['accs']\n",
        "    last_fold = checkpoint['last_fold']\n",
        "\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    optimizer_to(optimizer, 'cuda')\n",
        "    logger.info(\"=> loaded checkpoint '{}' (epoch {})\".format(\n",
        "      checkpoint_file, checkpoint['epoch']))\n",
        "\n",
        "  milestones = opts.lr_dec_epoch\n",
        "  lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
        "    optimizer, milestones, opts.lr_dec_factor,\n",
        "    last_epoch=last_epoch\n",
        "  )  # scheduler will be set to place given last from checkpoints\n",
        "  if opts.epoch_step > 0:\n",
        "    end_epoch = min(opts.end_epoch, opts.start_epoch + opts.epoch_step)\n",
        "  else:\n",
        "    end_epoch = opts.end_epoch\n",
        "\n",
        "  dump_input = torch.rand(\n",
        "    (16, opts.input_nc, opts.sz_pch[1], opts.sz_pch[0])\n",
        "  )\n",
        "\n",
        "\n",
        "  model = torch.nn.DataParallel(model, device_ids=opts.gpu_ids).cuda()                                     ###########WITH GPU\n",
        "  # model = torch.nn.DataParallel(model, device_ids=opts.gpu_ids)\n",
        "\n",
        "\n",
        "  logger.info(get_model_summary(model, dump_input.cuda()))                                     ###########WITH GPU\n",
        "  # logger.info(get_model_summary(model, dump_input))\n",
        "\n",
        "\n",
        "  n_iter = opts.trainIter  # only for test purpose     quick test\n",
        "  if (opts.mod_src == ['depth', \"psm\"]):\n",
        "      mod = \"both\"\n",
        "  else :\n",
        "      mod = opts.mod_src[0]\n",
        "\n",
        "  if not if_test:\n",
        "    for fold in range(last_fold, 5):\n",
        "      logger.info('Started fold {0}'.format(fold))\n",
        "      trainset = SMaLDataset(opts.ds_fd,fold=fold,covering=['uncovered','cover1','cover2'],phase=\"train\",\n",
        "                          clip=True,aug_param = opts.aug_param,modality=mod,swap_channels=opts.swap_channels)\n",
        "      train_loader = DataLoader(trainset, batch_size=16, shuffle=True)\n",
        "      valset = SMaLDataset(opts.ds_fd,fold=fold,clip=True,modality=mod,phase=\"val\",swap_channels=opts.swap_channels)\n",
        "      val_loader = DataLoader(valset, batch_size=300, shuffle=False)\n",
        "      for epoch in range(begin_epoch,end_epoch):\n",
        "        if opts.display_id > 0:\n",
        "          visualizer.reset()      # clean up the vis\n",
        "        # train for one epoch\n",
        "        # rst_trn = train(train_loader, SLP_rd_train, model, criterion, optimizer, epoch, n_iter=n_iter, logger=logger, opts=opts, visualizer=visualizer)\n",
        "        rst_trn = train(train_loader, model, criterion, optimizer, epoch, n_iter=n_iter, logger=logger, opts=opts, visualizer=visualizer)\n",
        "        losses += rst_trn['losses']\n",
        "        accs += rst_trn['accs']\n",
        "\n",
        "        # evaluate on validation set    to update\n",
        "        rst_test = validate(\n",
        "          val_loader, model, criterion, fold=fold,\n",
        "          n_iter=n_iter, logger=logger, opts=opts)   # save preds, gt, preds_in ori, idst_normed to recovery, error here for last epoch?\n",
        "\n",
        "        #HANDLE---\n",
        "        pck_all_1 = rst_test['pck1']\n",
        "        perf_indicator_1 = pck_all_1[-1][-1] # the last entry\n",
        "        pckh1 = np.array(pck_all_1)[:, -1]   # the last indicies     15 x 11 last\n",
        "        pck_all_05 = rst_test['pck05']\n",
        "        perf_indicator_05 = pck_all_05[-1][-1] # the last entry\n",
        "        pckh05 = np.array(pck_all_05)[:, -1]   # the last indicies     15 x 11 last\n",
        "        # print(np.array(pck_all))\n",
        "        titles_c = list(SMaL_configs['jointNames']) + ['total']\n",
        "        ut.prt_rst([pckh1], titles_c, ['pckh1'], fn_prt=logger.info)\n",
        "        ut.prt_rst([pckh05], titles_c, ['pckh0.5'], fn_prt=logger.info)\n",
        "        #---------\n",
        "\n",
        "        lr_scheduler.step()     # new version updating here\n",
        "        if perf_indicator_1 >= best_perf:\n",
        "          best_perf = perf_indicator_1\n",
        "          best_model = True\n",
        "        else:\n",
        "          best_model = False\n",
        "\n",
        "        logger.info('=> saving checkpoint to {}'.format(opts.model_dir))\n",
        "        ckp = {\n",
        "          'epoch': epoch + 1,     # epoch to next, after finish 0 this is 1\n",
        "          'model': opts.model,\n",
        "          'state_dict': model.module.state_dict(),\n",
        "          'best_state_dict': model.module.state_dict(),\n",
        "          'perf': perf_indicator_1,\n",
        "          'optimizer': optimizer.state_dict(),\n",
        "          'losses': losses,       # for later updating\n",
        "          'accs': accs,\n",
        "          'last_fold': fold\n",
        "        }\n",
        "        torch.save(ckp, os.path.join(opts.model_dir, 'checkpoint.pth'))\n",
        "        if best_model:\n",
        "          torch.save(ckp, os.path.join(opts.model_dir, 'model_best.pth'))\n",
        "        # save directly, if statebest save another\n",
        "      begin_epoch = 0\n",
        "    final_model_state_file = os.path.join(\n",
        "      opts.model_dir, 'final_state.pth'     # only after last iters\n",
        "    )\n",
        "    logger.info('=> saving final model state to {}'.format(\n",
        "      final_model_state_file)\n",
        "    )\n",
        "    torch.save(model.module.state_dict(), final_model_state_file)\n",
        "\n",
        "  # single test with loaded model, save the result\n",
        "  logger.info('----run final test----')\n",
        "  for fold in range(5):\n",
        "    testset = SMaLDataset('/content/drive/MyDrive/Final_Project/dataset/SMaL-224/',fold=fold,clip=True,modality=mod,phase=\"test\",swap_channels=opts.swap_channels)\n",
        "    test_loader = DataLoader(testset, batch_size=300, shuffle=False)\n",
        "    rst_test = validate(\n",
        "      test_loader, model, criterion,\n",
        "      n_iter=n_iter, logger=logger, opts=opts, if_svVis=True, fold=fold)  # save preds, gt, preds_in ori, idst_normed to recovery\n",
        "\n",
        "    #HANDLE-------------\n",
        "    pck_all_1 = rst_test['pck1']\n",
        "    # perf_indicator_1 = pck_all_1[-1][-1] # the last entry\n",
        "    pckh1 = np.array(pck_all_1)[:, -1]   # the last indicies     15 x 11 last\n",
        "    pck_all_05 = rst_test['pck05']\n",
        "    # perf_indicator_05 = pck_all_05[-1][-1] # the last entry\n",
        "    pckh05 = np.array(pck_all_05)[:, -1]   # the last indicies     15 x 11 last\n",
        "    # print(np.array(pck_all))\n",
        "    titles_c = list(SMaL_configs['jointNames']) + ['total']\n",
        "    ut.prt_rst([pckh1], titles_c, ['pckh1'], fn_prt=logger.info)\n",
        "    ut.prt_rst([pckh05], titles_c, ['pckh0.5'], fn_prt=logger.info)\n",
        "    pth_rst = path.join(opts.rst_dir, opts.nmTest + '.json')\n",
        "    with open(pth_rst, 'w') as f:\n",
        "      json.dump(rst_test, f)\n",
        "    #---------------\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KNBXCJe5fsP"
      },
      "source": [
        "# Predict with fusion model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvAUvKyEcFFo"
      },
      "source": [
        "Load image from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "o4pQFDlrFZLW",
        "outputId": "5b0dddef-ac1b-42dd-f45c-1e7026d2cf32"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# move to dataset location\n",
        "%cd /content/drive/MyDrive/Final_Project/dataset            \n",
        "\n",
        "cover_type = \"uncovered\"\n",
        "image_id = 23 ##<300\n",
        "\n",
        "depth_images = np.load('/content/drive/MyDrive/Final_Project/dataset/SMaL-All/depth.npz',mmap_mode='r')\n",
        "psm_images = np.load('/content/drive/MyDrive/Final_Project/dataset/SMaL-All/psm.npz',mmap_mode='r')\n",
        "color_images = np.load('/content/drive/MyDrive/Final_Project/dataset/SMaL-All/color.npz',mmap_mode='r')\n",
        "labels_img = np.load('/content/drive/MyDrive/Final_Project/dataset/SMaL-All/jnts.npy',mmap_mode='r')\n",
        "\n",
        "psm_image = psm_images[cover_type][image_id]\n",
        "depth_image = depth_images[cover_type][image_id]\n",
        "color_image = color_images[cover_type][image_id]\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "ax1 = fig.add_subplot(2,2,1)\n",
        "ax1.imshow(psm_image)\n",
        "ax2 = fig.add_subplot(2,2,2)\n",
        "ax2.imshow(depth_image)\n",
        "ax3 = fig.add_subplot(2,2,3)\n",
        "ax3.imshow(color_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC_YZJrnt6WC",
        "outputId": "2d57820f-de15-4c6a-bc86-27c80afc4045"
      },
      "outputs": [],
      "source": [
        "###move to where the codebase is located\n",
        "%cd /content/drive/MyDrive/Final_Project/code/Fusion_Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmI0JII_cKBW"
      },
      "source": [
        "Calculate mean and std for image normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmQG5HAfY8-h",
        "outputId": "bdf5e633-9aa1-46d3-da77-c43e6538c6a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5.8949493e+02 1.1351888e-02] [59.654747    0.07786007]\n"
          ]
        }
      ],
      "source": [
        "means = []\n",
        "stds = []\n",
        "for fold in range(5):\n",
        "  testset = SMaLDataset('/content/drive/MyDrive/Final_Project/dataset/SMaL-224/',fold=fold,clip=True,modality=\"both\",phase=\"test\",swap_channels=False)\n",
        "  test_loader = DataLoader(testset, batch_size=1, shuffle=True)\n",
        "  with torch.no_grad():\n",
        "    for i, inp_dct in enumerate(test_loader):\n",
        "      # compute output\n",
        "      input = inp_dct['pch']\n",
        "      mean = inp_dct[\"mean\"]\n",
        "      std = inp_dct[\"std\"]\n",
        "      means.append(mean.cpu().detach().numpy())\n",
        "      stds.append(std.cpu().detach().numpy())\n",
        "avg_mean = np.vstack(means).mean(axis=0)\n",
        "avg_std = np.vstack(stds).mean(axis=0)\n",
        "print(avg_mean, avg_std)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jszW0ruBcQ0v"
      },
      "source": [
        "Image preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VPxf4hqMPmC",
        "outputId": "de1ad866-bb27-4335-b163-ab9476997a60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 256, 256])"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "depth_image_exp = np.expand_dims(depth_image,axis = 0)\n",
        "psm_image_exp = np.expand_dims(psm_image,axis = 0)\n",
        "input_image_stacked = np.stack([depth_image,psm_image], axis = 2)\n",
        "input_image_exp = np.expand_dims(input_image_stacked, axis=0)\n",
        "input_image_exp[:,:,:,0] = np.clip(input_image_exp[:,:,:,0],400,800)\n",
        "mean = avg_mean\n",
        "std = avg_std\n",
        "img = input_image_exp[0,:,:,:]\n",
        "img_resized = cv2.resize(img, dsize=(256,256), interpolation=cv2.INTER_CUBIC)\n",
        "img_height, img_width, img_channel = img_resized.shape\n",
        "bb = [0,0,img_width,img_height]  # full image bb , make square bb\n",
        "bb = ut.adj_bb(bb, rt_xy=1)\n",
        "scale, rot, do_flip, color_scale, do_occlusion = 1.0, 0.0, False, [1.0, 1.0, 1.0], False\n",
        "img_patch, trans = generate_patch_image(img_resized, bb, do_flip, scale, rot, do_occlusion, input_shape=(256,256))\n",
        "img_channels = img_patch.shape[2]\n",
        "for i in range(img_channels):\n",
        "  img_patch[:, :, i] = img_patch[:, :, i] * color_scale[i]\n",
        "trans_tch = transforms.Compose([transforms.ToTensor(),\n",
        "          transforms.Normalize(mean=mean, std=std)]\n",
        "        )\n",
        "pch_tch = trans_tch(img_patch)[None,:,:,:]\n",
        "pch_tch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSReSgjccW7K"
      },
      "source": [
        "Initialise the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EU2Eaxf-uOw"
      },
      "outputs": [],
      "source": [
        "\n",
        "from model.HRposeFuseNetNewUnweighted_v2 import get_pose_net\n",
        "\n",
        "model = \"HRposeFuseNetNewUnweighted_v2\"\n",
        "mod_src = [\"depth\", \"psm\"]\n",
        "fuse_model_path = '/content/drive/MyDrive/Final_Project/code/Fusion_Network/output/SMaL_depth_PM_2_iaff_dropout/model_dump'\n",
        "\n",
        "model =  get_pose_net(in_ch=2, out_ch=14, fuse_stage=2, fuse_type=\"iAFF\", mod_src=mod_src)\n",
        "\n",
        "checkpoint_file = os.path.join(fuse_model_path,'model_best.pth')\n",
        "\n",
        "checkpoint = torch.load(checkpoint_file)        ###WITH GPU\n",
        "# checkpoint = torch.load(checkpoint_file, map_location=torch.device('cpu'))\n",
        "\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "model.cuda()      ###WITH GPU\n",
        "\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "940aPPE5ca7R"
      },
      "source": [
        "Pose prediction and visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "QSFrq0w1558X"
      },
      "outputs": [],
      "source": [
        "pred = model(pch_tch.cuda())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "92cB7CDmN9Qc"
      },
      "outputs": [],
      "source": [
        "from utils.utils_ds import get_max_preds\n",
        "end = time.time()\n",
        "out_shp = (64,64)\n",
        "sz_pch = (256,256)\n",
        "preds_hm = []\n",
        "bbs = []\n",
        "li_joints_ori = []\n",
        "li_joints_vis = []\n",
        "li_l_std_ori = []\n",
        "outputs =pred[\"output\"]\n",
        "\n",
        "if isinstance(outputs, list):\n",
        "  output = outputs[-1]\n",
        "else:\n",
        "  output = outputs\n",
        "\n",
        "pred_hm, _ = get_max_preds(output.cpu().detach().numpy())\n",
        "pred2d_patch = np.ones((SMaL_configs[\"numJoints\"], 3))  # 3rd for  vis\n",
        "pred2d_patch[:,:2] = pred_hm[0] / out_shp[0] * sz_pch[1]      # only first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "JLBHUzCXOn0Z",
        "outputId": "3425bc2f-6bb3-43c2-fdb2-b7b6548e962c"
      },
      "outputs": [],
      "source": [
        "_,(ax1,ax2) = plt.subplots(1,2, figsize=(15,15))\n",
        "color_image_resized = cv2.resize(color_image, dsize=(256,256), interpolation=cv2.INTER_CUBIC)\n",
        "plotImage(ax1, color_image_resized,0)\n",
        "plot2DJoints(ax1, pred2d_patch,  SMaL_configs[\"connectedJoints\"], SMaL_configs[\"gtjointColours\"])\n",
        "\n",
        "plotImage(ax2, img_patch[:,:,0],0)\n",
        "plot2DJoints(ax2, pred2d_patch,  SMaL_configs[\"connectedJoints\"], SMaL_configs[\"gtjointColours\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2Tye-KQbOyU"
      },
      "source": [
        "Predicted heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "9G3lZI2u72d-",
        "outputId": "71a30ae0-616a-45ee-c7c3-3234204c146d"
      },
      "outputs": [],
      "source": [
        "\n",
        "t = pred['output'][0][0]\n",
        "plt.imshow(t.cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmfkeOY6bUI-"
      },
      "source": [
        "Visualise using dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "zuIV99__RWvH",
        "outputId": "032e101b-b7c8-4d89-ea6a-749b0c21c48d"
      },
      "outputs": [],
      "source": [
        "out_shp = (64,64)\n",
        "sz_pch = (256,256)\n",
        "testset = SMaLDataset('/content/drive/MyDrive/Final_Project/dataset/SMaL-224/',fold=4,clip=True,modality=\"both\",phase=\"test\",swap_channels=False)\n",
        "test_loader = DataLoader(testset, batch_size=1, shuffle=True)\n",
        "with torch.no_grad():\n",
        "  for i, inp_dct in enumerate(test_loader):\n",
        "    # compute output\n",
        "    input = inp_dct['pch']\n",
        "    print(input.shape)\n",
        "    mean = inp_dct[\"mean\"]\n",
        "    std = inp_dct[\"std\"]\n",
        "    outputs = model(input.cuda())\n",
        "    outputs =outputs[\"output\"]\n",
        "    if isinstance(outputs, list):\n",
        "      output = outputs[-1]\n",
        "    else:\n",
        "      output = outputs\n",
        "    output_ori = output.clone()     # original output of original image\n",
        "    # _, avg_acc, cnt, pred_hm = accuracy(output.cpu().numpy(),\n",
        "    #                                   target.cpu().numpy())\n",
        "    pred_hm = get_max_preds(output.cpu().numpy())\n",
        "    pred2d_patch = np.ones((14, 3))  # 3rd for  vis\n",
        "    ax = plt.subplot(1,2,1)\n",
        "    plotImage(ax, input[0],0)\n",
        "    pred2d_patch[:,:2] = pred_hm[0] / out_shp[0] * sz_pch[1]\n",
        "    plot2DJoints(ax, pred2d_patch,  SMaL_configs[\"connectedJoints\"], SMaL_configs[\"gtjointColours\"])\n",
        "    break\n",
        "\n",
        "print(mean, std)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
